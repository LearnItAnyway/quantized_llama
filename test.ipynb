{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f39158-79e4-4c38-ad17-2dbe9bf23b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import json\n",
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Sequence\n",
    "import gc\n",
    "\n",
    "import io\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import LlamaModel, LlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaRMSNorm, LlamaRotaryEmbedding, LlamaDecoderLayer\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import Trainer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "from transformers.utils import is_sagemaker_mp_enabled\n",
    "from transformers.trainer_utils import ShardedDDPOption\n",
    "from transformers.pytorch_utils import ALL_LAYERNORM_LAYERS\n",
    "from transformers import GenerationConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea040ba-4fda-465f-96a8-2acdcfa7e0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load custom LlamaModel\n",
    "from modeling_llama import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee6025c-cac4-4f0a-815e-6e8211f49019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install git lfs, then get the model \n",
    "# !git clone https://huggingface.co/LearnItAnyway/llama-7b-hf-28q_4bit-128g_WVU\n",
    "model_name = './llama-7b-hf-28q_4bit-128g_WVU'\n",
    "# You can also use LearnItAnyway/llama-13b-hf-35q_4bit-128g_WVU or LearnItAnyway/llama-30b-hf-53q_4bit-128g_WVU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331e93f1-ee02-4b24-865d-ca1fc664f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "ended\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af36cfff543480a982b31f6c6679674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7d0b3-d132-4ea7-83d2-9d5c0cf5e094",
   "metadata": {},
   "source": [
    "If model has quant_bits, quant_groupsize, and,  quant_layers, the Llama model, quantized first `quant_layers` layers has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83053866-4c92-4f02-998d-1e5136ed8e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"_name_or_path\": \"./llama-7b-hf-28q_4bit-128g_WVU\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"quant_bits\": 4,\n",
      "  \"quant_groupsize\": 128,\n",
      "  \"quant_layers\": 28,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.29.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)\n",
    "#print('Num quantized layer :', model.config.quant_layers)\n",
    "#print('Num quantized layer bits and groupsize:', model.config.quant_bits, ',', model.config.quant_groupsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3528cf08-1b33-454b-9a7b-7e0a015f1399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.half()\n",
    "model.cuda()\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080b7930-6c5e-4cae-bd81-8c206e3c5bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, input=None):\n",
    "    return f\"\"\"{instruction}\n",
    "#### Response:\n",
    "\"\"\"\n",
    "\n",
    "def evaluate(\n",
    "        batch_data,\n",
    "        input=None,\n",
    "        temperature=1,\n",
    "        top_p=0.9,\n",
    "        top_k=40,\n",
    "        num_beams=1,\n",
    "        max_new_tokens=2048,\n",
    "        **kwargs,\n",
    "):\n",
    "    prompts = generate_prompt(batch_data, input)\n",
    "    #prompts = [generate_prompt(b, input) for b in batch_data]\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        num_beams=num_beams,\n",
    "        **kwargs,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    s = generation_output.sequences\n",
    "    output = tokenizer.batch_decode(s, skip_special_tokens=False)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1e84bc-593f-4cba-adae-3845eac6e862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "Can you provide a list of healthy habits to maintain a healthy lifestyle? Please format your response as an HTML page with bullet points. <html> <body> <h3>Healthy Habits:</h3> <ul> <li>Eating a balanced diet with plenty of fruits and vegetables.</li> <li>Engaging in regular physical activity, such as walking, running, or cycling.</li> <li>Getting enough sleep each night, ideally 7-8 hours.</li> <li>Staying hydrated by drinking plenty of water throughout the day.</li> <li>Limiting alcohol consumption and avoiding smoking.</li> <li>Managing stress through relaxation techniques like meditation or yoga.</li> <li>Regularly visiting a healthcare provider for check-ups and preventative care.</li> </ul> </body> </html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2313d8f-3f8c-456e-bcef-f13ca9966577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112b41f9-c2af-47f1-ba2a-50227f8a1f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.409578800201416 \n",
      " <s> \n",
      "Can you provide a list of healthy habits to maintain a healthy lifestyle? Please format your response as an HTML page with bullet points. <html> <body> <h3>Healthy Habits:</h3> <ul> <li>Eating a balanced diet with plenty of fruits and vegetables.</li> <li>Engaging in regular physical activity, such as walking, running, or cycling.</li> <li>Getting enough sleep each night, ideally 7-8 hours.</li> <li>Staying hydrated by drinking plenty of water throughout the day.</li> <li>Limiting alcohol consumption and avoiding smoking.</li> <li>Managing stress through relaxation techniques like meditation or yoga.</li> <li>Regularly visiting a healthcare provider for check-ups and preventative care.</li> </ul> </body> </html>\n",
      "\n",
      "#### Response:\n",
      "Here's an example HTML page with bullet points:\n",
      "```\n",
      "Healthy Habits:\n",
      "1. Eating a balanced diet with plenty of fruits and vegetables.\n",
      "2. Engaging in regular physical activity, such as walking, running, or cycling.\n",
      "3. Getting enough sleep each night, ideally 7-8 hours.\n",
      "4. Staying hydrated by drinking plenty of water throughout the day.\n",
      "5. Limiting alcohol consumption and avoiding smoking.\n",
      "6. Managing stress through relaxation techniques like meditation or yoga.\n",
      "7. Regularly visiting a healthcare provider for check-ups and preventative care.\n",
      "```\n",
      "This is a great example of how to format your HTML page with bullet points.</s>\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "output = evaluate(data)\n",
    "e_time = time.time()\n",
    "\n",
    "print(e_time-s_time, '\\n' ,output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a3469-f4c0-4c32-8e00-a4e909d09fd6",
   "metadata": {},
   "source": [
    "### After generate the response, it is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0f179f-9b3d-4fd4-99a5-2d7370e66a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.025457143783569 \n",
      " <s> \n",
      "Can you provide a list of healthy habits to maintain a healthy lifestyle? Please format your response as an HTML page with bullet points. <html> <body> <h3>Healthy Habits:</h3> <ul> <li>Eating a balanced diet with plenty of fruits and vegetables.</li> <li>Engaging in regular physical activity, such as walking, running, or cycling.</li> <li>Getting enough sleep each night, ideally 7-8 hours.</li> <li>Staying hydrated by drinking plenty of water throughout the day.</li> <li>Limiting alcohol consumption and avoiding smoking.</li> <li>Managing stress through relaxation techniques like meditation or yoga.</li> <li>Regularly visiting a healthcare provider for check-ups and preventative care.</li> </ul> </body> </html>\n",
      "\n",
      "#### Response:\n",
      "Here's an example HTML page with bullet points:\n",
      "```\n",
      "Healthy Habits:\n",
      "1. Eating a balanced diet with plenty of fruits and vegetables.\n",
      "2. Engaging in regular physical activity, such as walking, running, or cycling.\n",
      "3. Getting enough sleep each night, ideally 7-8 hours.\n",
      "4. Staying hydrated by drinking plenty of water throughout the day.\n",
      "5. Limiting alcohol consumption and avoiding smoking.\n",
      "6. Managing stress through relaxation techniques like meditation or yoga.\n",
      "7. Regularly visiting a healthcare provider for check-ups and preventative care.\n",
      "```\n",
      "This is a great example of how to format your HTML page with bullet points.</s>\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "output = evaluate(data)\n",
    "e_time = time.time()\n",
    "\n",
    "print(e_time-s_time, '\\n' ,output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b06c7d38-7939-4680-823e-5392d6745285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    import tqdm, json\n",
    "\n",
    "    input_data_path = './WizardLM/data/WizardLM_testset.jsonl'\n",
    "    output_data_path = '7b_output_WizardLM_testset.jsonl'\n",
    "\n",
    "    input_data = open(input_data_path, mode='r', encoding='utf-8')\n",
    "    output_data = open(output_data_path, mode='w', encoding='utf-8')\n",
    "    for num, line in tqdm.tqdm(enumerate(input_data.readlines())):\n",
    "        one_data = json.loads(line)\n",
    "        id = one_data[\"idx\"]\n",
    "        instruction = one_data[\"Instruction\"]\n",
    "        _output = evaluate(instruction, max_new_tokens=256)\n",
    "        try: \n",
    "            final_output = _output[0].split(\"### Response:\")[1].strip()\n",
    "            new_data = {\n",
    "                \"id\": id,\n",
    "                \"instruction\": instruction,\n",
    "                \"output\": final_output\n",
    "            }\n",
    "            output_data.write(json.dumps(new_data) + '\\n')\n",
    "        except:\n",
    "            pass\n",
    "    print('End.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
